{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gender Classification from Text Blog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset into notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/hoangvo/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/hoangvo/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/hoangvo/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import string\n",
    "import nltk\n",
    "nltk.download()\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import nltk.corpus\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import re\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!  conda install  openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#df = pd.read_excel('blog-gender-dataset/blog-gender-dataset.xlsx', engine='openpyxl')\n",
    "headers = [\"text\", \"class\"]\n",
    "text_df = pd.read_csv('blog-gender-dataset/blog-gender-dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Guest Demo: Eric Iverson’s Itty Bitty Search\\...</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Who moved my Cheese???   The world has been de...</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yesterday I attended a biweekly meeting of an...</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Liam is nothing like Natalie. Natalie never w...</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In the EU we have browser choice, but few know...</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3226</th>\n",
       "      <td>It was a scavenger style race with checkpoints...</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3227</th>\n",
       "      <td>Finally! I got a full day's work done. Almost ...</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3228</th>\n",
       "      <td>At the height of laughter, the universe is flu...</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3229</th>\n",
       "      <td>I like birds, especially woodpeckers and MOST ...</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3230</th>\n",
       "      <td>Oh friends, it's finally here! I thought the m...</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3231 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text class\n",
       "0      Guest Demo: Eric Iverson’s Itty Bitty Search\\...     M\n",
       "1     Who moved my Cheese???   The world has been de...     M\n",
       "2      Yesterday I attended a biweekly meeting of an...     M\n",
       "3      Liam is nothing like Natalie. Natalie never w...     F\n",
       "4     In the EU we have browser choice, but few know...     M\n",
       "...                                                 ...   ...\n",
       "3226  It was a scavenger style race with checkpoints...     M\n",
       "3227  Finally! I got a full day's work done. Almost ...     F\n",
       "3228  At the height of laughter, the universe is flu...     M\n",
       "3229  I like birds, especially woodpeckers and MOST ...     M\n",
       "3230  Oh friends, it's finally here! I thought the m...     F\n",
       "\n",
       "[3231 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df = text_df.iloc[:, [0, 1]]\n",
    "text_df.columns = headers\n",
    "text_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3231, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     3226\n",
       "unique       8\n",
       "top          M\n",
       "freq      1546\n",
       "Name: class, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df[\"class\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3231 entries, 0 to 3230\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    3224 non-null   object\n",
      " 1   class   3226 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 50.6+ KB\n"
     ]
    }
   ],
   "source": [
    "text_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1546, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df[text_df['class']==\"M\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1390, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df[text_df['class']==\"F\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Guest Demo: Eric Iverson’s Itty Bitty Search\\...</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Who moved my Cheese???   The world has been de...</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yesterday I attended a biweekly meeting of an...</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Liam is nothing like Natalie. Natalie never w...</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In the EU we have browser choice, but few know...</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3226</th>\n",
       "      <td>It was a scavenger style race with checkpoints...</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3227</th>\n",
       "      <td>Finally! I got a full day's work done. Almost ...</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3228</th>\n",
       "      <td>At the height of laughter, the universe is flu...</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3229</th>\n",
       "      <td>I like birds, especially woodpeckers and MOST ...</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3230</th>\n",
       "      <td>Oh friends, it's finally here! I thought the m...</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3224 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text class\n",
       "0      Guest Demo: Eric Iverson’s Itty Bitty Search\\...     M\n",
       "1     Who moved my Cheese???   The world has been de...     M\n",
       "2      Yesterday I attended a biweekly meeting of an...     M\n",
       "3      Liam is nothing like Natalie. Natalie never w...     F\n",
       "4     In the EU we have browser choice, but few know...     M\n",
       "...                                                 ...   ...\n",
       "3226  It was a scavenger style race with checkpoints...     M\n",
       "3227  Finally! I got a full day's work done. Almost ...     F\n",
       "3228  At the height of laughter, the universe is flu...     M\n",
       "3229  I like birds, especially woodpeckers and MOST ...     M\n",
       "3230  Oh friends, it's finally here! I thought the m...     F\n",
       "\n",
       "[3224 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df = text_df.dropna()\n",
    "text_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hoangvo/anaconda3/envs/Data-mining/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/hoangvo/anaconda3/envs/Data-mining/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/hoangvo/anaconda3/envs/Data-mining/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/hoangvo/anaconda3/envs/Data-mining/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/hoangvo/anaconda3/envs/Data-mining/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "/Users/hoangvo/anaconda3/envs/Data-mining/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "M    1677\n",
       "F    1547\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df[\"class\"] = text_df[\"class\"].replace(' F', 'F')\n",
    "text_df[\"class\"] = text_df[\"class\"].replace('f', 'F')\n",
    "text_df[\"class\"] = text_df[\"class\"].replace('F ', 'F')\n",
    "text_df[\"class\"] = text_df[\"class\"].replace(' M', 'M')\n",
    "text_df[\"class\"] = text_df[\"class\"].replace('m', 'M')\n",
    "text_df[\"class\"] = text_df[\"class\"].replace(' M ', 'M')\n",
    "text_df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df2 = pd.read_json('data/train.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df2 = text_df2[[\"post\",\"gender\"]]\n",
    "text_df2.columns = headers\n",
    "text_df2[\"class\"] = text_df2[\"class\"].replace('female', 'F')\n",
    "text_df2[\"class\"] = text_df2[\"class\"].replace('male', 'M')\n",
    "text_df2 = text_df2[text_df2[\"text\"]!= \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_M = [text_df1[text_df1[\"class\"]==\"M\"], text_df2[text_df2[\"class\"]==\"M\"]]\n",
    "df_M = [text_df2[text_df2[\"class\"]==\"M\"]]\n",
    "df_M = pd.concat(df_M)\n",
    "df_M = df_M.sample(frac=1).reset_index(drop=True)\n",
    "#df_F = [text_df1[text_df1[\"class\"]==\"F\"], text_df2[text_df2[\"class\"]==\"F\"]]\n",
    "df_F = [text_df2[text_df2[\"class\"]==\"F\"]]\n",
    "df_F = pd.concat(df_F)\n",
    "df_F = df_F.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text_df = [text_df, df_M[:400], df_F[:400]]\n",
    "text_df = [ df_M[:100000], df_F[:100000]]\n",
    "text_df = pd.concat(text_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df = text_df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df = text_df.dropna()\n",
    "text_df = text_df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nltk\n",
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/nlp-for-beginners-cleaning-preprocessing-text-data-ae8e306bef0f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hmmmm, I haven't done much this week. Me and Britt went to the Mall of Georgia on monday, yesterday I did nothing, and today, me and my mom went out to eat and then we went out to dinner for my dad's birthday at Macaroni Grill. Tomorrow will be busy. Registration at 8:30, then FINALLY I get my license at 10:30. I hate to admit that I'm almost 18 and don't have my license, so after tomorrow I am FREE. Then, tomorrow night, I am either going to see Blues Traveler for free at the Variety Playhouse with Britt or to see Bob Margolin at Blind Willie's with my dad. I'd rather see Margolin again because he is a badass. Oh well, that's all. Ron Isley is the biggest pimp ever.\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df[\"text\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove html\n",
    "def remove_html(text):\n",
    "    soup = BeautifulSoup(text, 'lxml')\n",
    "    html_free = soup.get_text()\n",
    "    return html_free\n",
    "\n",
    "#remove punctuation\n",
    "def remove_punctuation(text):\n",
    "    punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "    no_punct = \" \".join([c for c in text if c not in punctuations])\n",
    "    return no_punct\n",
    "#textclean = text_df['text'].apply(lambda x : remove_punctuation(x))\n",
    "#instantiate tokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "#textclean = textclean.apply(lambda x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I just got word that I was not cast in the Law...</td>\n",
       "      <td>M</td>\n",
       "      <td>i just got word that i was not cast in the law...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hmmmm, I haven't done much this week. Me and B...</td>\n",
       "      <td>M</td>\n",
       "      <td>hmmmm i havent done much this week me and brit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i'm not even sure what memorial day is suppose...</td>\n",
       "      <td>F</td>\n",
       "      <td>im not even sure what memorial day is supposed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ok, so we are having a classic book crisis at ...</td>\n",
       "      <td>F</td>\n",
       "      <td>ok so we are having a classic book crisis at o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>urlLink    Steve Newton talking to Laura at hi...</td>\n",
       "      <td>F</td>\n",
       "      <td>urllink    steve newton talking to laura at hi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text class  \\\n",
       "0  I just got word that I was not cast in the Law...     M   \n",
       "1  Hmmmm, I haven't done much this week. Me and B...     M   \n",
       "2  i'm not even sure what memorial day is suppose...     F   \n",
       "3  ok, so we are having a classic book crisis at ...     F   \n",
       "4  urlLink    Steve Newton talking to Laura at hi...     F   \n",
       "\n",
       "                                          text_clean  \n",
       "0  i just got word that i was not cast in the law...  \n",
       "1  hmmmm i havent done much this week me and brit...  \n",
       "2  im not even sure what memorial day is supposed...  \n",
       "3  ok so we are having a classic book crisis at o...  \n",
       "4  urllink    steve newton talking to laura at hi...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def  clean_text(df, text_field, new_text_field_name):\n",
    "    df[new_text_field_name] = df[text_field].str.lower()\n",
    "    df[new_text_field_name] = df[new_text_field_name].apply(lambda elem: re.sub(r\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", elem))  \n",
    "    # remove numbers\n",
    "    df[new_text_field_name] = df[new_text_field_name].apply(lambda elem: re.sub(r\"\\d+\", \"\", elem))\n",
    "    \n",
    "    return df\n",
    "data_clean = clean_text(text_df, 'text', 'text_clean')\n",
    "data_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I just got word that I was not cast in the Law...</td>\n",
       "      <td>M</td>\n",
       "      <td>got word cast law order episode good news cast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hmmmm, I haven't done much this week. Me and B...</td>\n",
       "      <td>M</td>\n",
       "      <td>hmmmm havent done much week britt went mall ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i'm not even sure what memorial day is suppose...</td>\n",
       "      <td>F</td>\n",
       "      <td>im even sure memorial day supposed celebrate v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ok, so we are having a classic book crisis at ...</td>\n",
       "      <td>F</td>\n",
       "      <td>ok classic book crisis housewe cannot find har...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>urlLink    Steve Newton talking to Laura at hi...</td>\n",
       "      <td>F</td>\n",
       "      <td>urllink steve newton talking laura party urllink</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text class  \\\n",
       "0  I just got word that I was not cast in the Law...     M   \n",
       "1  Hmmmm, I haven't done much this week. Me and B...     M   \n",
       "2  i'm not even sure what memorial day is suppose...     F   \n",
       "3  ok, so we are having a classic book crisis at ...     F   \n",
       "4  urlLink    Steve Newton talking to Laura at hi...     F   \n",
       "\n",
       "                                          text_clean  \n",
       "0  got word cast law order episode good news cast...  \n",
       "1  hmmmm havent done much week britt went mall ge...  \n",
       "2  im even sure memorial day supposed celebrate v...  \n",
       "3  ok classic book crisis housewe cannot find har...  \n",
       "4   urllink steve newton talking laura party urllink  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import nltk.corpus\n",
    "#nltk.download('stopwords')\n",
    "#from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "data_clean['text_clean'] = data_clean['text_clean'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "data_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'got word cast law order episode good news casting director show called manager got audition first place give feedback said wasnt director mind role gave good read probably law order future besides cast could ask ive game ten days im pretty happy far'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean['text_clean'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>text_tokens</th>\n",
       "      <th>text_tokens_stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I just got word that I was not cast in the Law...</td>\n",
       "      <td>M</td>\n",
       "      <td>got word cast law order episode good news cast...</td>\n",
       "      <td>[got, word, cast, law, order, episode, good, n...</td>\n",
       "      <td>[got, word, cast, law, order, episod, good, ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hmmmm, I haven't done much this week. Me and B...</td>\n",
       "      <td>M</td>\n",
       "      <td>hmmmm havent done much week britt went mall ge...</td>\n",
       "      <td>[hmmmm, havent, done, much, week, britt, went,...</td>\n",
       "      <td>[hmmmm, havent, done, much, week, britt, went,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i'm not even sure what memorial day is suppose...</td>\n",
       "      <td>F</td>\n",
       "      <td>im even sure memorial day supposed celebrate v...</td>\n",
       "      <td>[im, even, sure, memorial, day, supposed, cele...</td>\n",
       "      <td>[im, even, sure, memori, day, suppos, celebr, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ok, so we are having a classic book crisis at ...</td>\n",
       "      <td>F</td>\n",
       "      <td>ok classic book crisis housewe cannot find har...</td>\n",
       "      <td>[ok, classic, book, crisis, housewe, can, not,...</td>\n",
       "      <td>[ok, classic, book, crisi, housew, can, not, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>urlLink    Steve Newton talking to Laura at hi...</td>\n",
       "      <td>F</td>\n",
       "      <td>urllink steve newton talking laura party urllink</td>\n",
       "      <td>[urllink, steve, newton, talking, laura, party...</td>\n",
       "      <td>[urllink, steve, newton, talk, laura, parti, u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text class  \\\n",
       "0  I just got word that I was not cast in the Law...     M   \n",
       "1  Hmmmm, I haven't done much this week. Me and B...     M   \n",
       "2  i'm not even sure what memorial day is suppose...     F   \n",
       "3  ok, so we are having a classic book crisis at ...     F   \n",
       "4  urlLink    Steve Newton talking to Laura at hi...     F   \n",
       "\n",
       "                                          text_clean  \\\n",
       "0  got word cast law order episode good news cast...   \n",
       "1  hmmmm havent done much week britt went mall ge...   \n",
       "2  im even sure memorial day supposed celebrate v...   \n",
       "3  ok classic book crisis housewe cannot find har...   \n",
       "4   urllink steve newton talking laura party urllink   \n",
       "\n",
       "                                         text_tokens  \\\n",
       "0  [got, word, cast, law, order, episode, good, n...   \n",
       "1  [hmmmm, havent, done, much, week, britt, went,...   \n",
       "2  [im, even, sure, memorial, day, supposed, cele...   \n",
       "3  [ok, classic, book, crisis, housewe, can, not,...   \n",
       "4  [urllink, steve, newton, talking, laura, party...   \n",
       "\n",
       "                                    text_tokens_stem  \n",
       "0  [got, word, cast, law, order, episod, good, ne...  \n",
       "1  [hmmmm, havent, done, much, week, britt, went,...  \n",
       "2  [im, even, sure, memori, day, suppos, celebr, ...  \n",
       "3  [ok, classic, book, crisi, housew, can, not, f...  \n",
       "4  [urllink, steve, newton, talk, laura, parti, u...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import nltk \n",
    "#nltk.download('punkt')\n",
    "#from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "data_clean['text_tokens'] = data_clean['text_clean'].apply(lambda x: word_tokenize(x))\n",
    "\n",
    "def word_stemmer(text):\n",
    "    stem_text = [PorterStemmer().stem(i) for i in text]\n",
    "    return stem_text\n",
    "\n",
    "data_clean['text_tokens_stem'] = data_clean['text_tokens'].apply(lambda x: word_stemmer(x))\n",
    "data_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>text_tokens</th>\n",
       "      <th>text_tokens_stem</th>\n",
       "      <th>text_tokens_lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I just got word that I was not cast in the Law...</td>\n",
       "      <td>M</td>\n",
       "      <td>got word cast law order episode good news cast...</td>\n",
       "      <td>[got, word, cast, law, order, episode, good, n...</td>\n",
       "      <td>[got, word, cast, law, order, episod, good, ne...</td>\n",
       "      <td>[got, word, cast, law, order, episode, good, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hmmmm, I haven't done much this week. Me and B...</td>\n",
       "      <td>M</td>\n",
       "      <td>hmmmm havent done much week britt went mall ge...</td>\n",
       "      <td>[hmmmm, havent, done, much, week, britt, went,...</td>\n",
       "      <td>[hmmmm, havent, done, much, week, britt, went,...</td>\n",
       "      <td>[hmmmm, havent, done, much, week, britt, went,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i'm not even sure what memorial day is suppose...</td>\n",
       "      <td>F</td>\n",
       "      <td>im even sure memorial day supposed celebrate v...</td>\n",
       "      <td>[im, even, sure, memorial, day, supposed, cele...</td>\n",
       "      <td>[im, even, sure, memori, day, suppos, celebr, ...</td>\n",
       "      <td>[im, even, sure, memorial, day, supposed, cele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ok, so we are having a classic book crisis at ...</td>\n",
       "      <td>F</td>\n",
       "      <td>ok classic book crisis housewe cannot find har...</td>\n",
       "      <td>[ok, classic, book, crisis, housewe, can, not,...</td>\n",
       "      <td>[ok, classic, book, crisi, housew, can, not, f...</td>\n",
       "      <td>[ok, classic, book, crisis, housewe, can, not,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>urlLink    Steve Newton talking to Laura at hi...</td>\n",
       "      <td>F</td>\n",
       "      <td>urllink steve newton talking laura party urllink</td>\n",
       "      <td>[urllink, steve, newton, talking, laura, party...</td>\n",
       "      <td>[urllink, steve, newton, talk, laura, parti, u...</td>\n",
       "      <td>[urllink, steve, newton, talking, laura, party...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text class  \\\n",
       "0  I just got word that I was not cast in the Law...     M   \n",
       "1  Hmmmm, I haven't done much this week. Me and B...     M   \n",
       "2  i'm not even sure what memorial day is suppose...     F   \n",
       "3  ok, so we are having a classic book crisis at ...     F   \n",
       "4  urlLink    Steve Newton talking to Laura at hi...     F   \n",
       "\n",
       "                                          text_clean  \\\n",
       "0  got word cast law order episode good news cast...   \n",
       "1  hmmmm havent done much week britt went mall ge...   \n",
       "2  im even sure memorial day supposed celebrate v...   \n",
       "3  ok classic book crisis housewe cannot find har...   \n",
       "4   urllink steve newton talking laura party urllink   \n",
       "\n",
       "                                         text_tokens  \\\n",
       "0  [got, word, cast, law, order, episode, good, n...   \n",
       "1  [hmmmm, havent, done, much, week, britt, went,...   \n",
       "2  [im, even, sure, memorial, day, supposed, cele...   \n",
       "3  [ok, classic, book, crisis, housewe, can, not,...   \n",
       "4  [urllink, steve, newton, talking, laura, party...   \n",
       "\n",
       "                                    text_tokens_stem  \\\n",
       "0  [got, word, cast, law, order, episod, good, ne...   \n",
       "1  [hmmmm, havent, done, much, week, britt, went,...   \n",
       "2  [im, even, sure, memori, day, suppos, celebr, ...   \n",
       "3  [ok, classic, book, crisi, housew, can, not, f...   \n",
       "4  [urllink, steve, newton, talk, laura, parti, u...   \n",
       "\n",
       "                                   text_tokens_lemma  \n",
       "0  [got, word, cast, law, order, episode, good, n...  \n",
       "1  [hmmmm, havent, done, much, week, britt, went,...  \n",
       "2  [im, even, sure, memorial, day, supposed, cele...  \n",
       "3  [ok, classic, book, crisis, housewe, can, not,...  \n",
       "4  [urllink, steve, newton, talking, laura, party...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nltk.download('wordnet')\n",
    "#from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def word_lemmatizer(text):\n",
    "    lem_text = [WordNetLemmatizer().lemmatize(i) for i in text]\n",
    "    return lem_text\n",
    "\n",
    "data_clean['text_tokens_lemma'] = data_clean['text_tokens'].apply(lambda x: word_lemmatizer(x))\n",
    "data_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/hoangvo/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>text_tokens</th>\n",
       "      <th>text_tokens_stem</th>\n",
       "      <th>text_tokens_lemma</th>\n",
       "      <th>text_tokens_pos_tagged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I just got word that I was not cast in the Law...</td>\n",
       "      <td>M</td>\n",
       "      <td>got word cast law order episode good news cast...</td>\n",
       "      <td>[got, word, cast, law, order, episode, good, n...</td>\n",
       "      <td>[got, word, cast, law, order, episod, good, ne...</td>\n",
       "      <td>[got, word, cast, law, order, episode, good, n...</td>\n",
       "      <td>[(got, VBD), (word, NN), (cast, NN), (law, NN)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hmmmm, I haven't done much this week. Me and B...</td>\n",
       "      <td>M</td>\n",
       "      <td>hmmmm havent done much week britt went mall ge...</td>\n",
       "      <td>[hmmmm, havent, done, much, week, britt, went,...</td>\n",
       "      <td>[hmmmm, havent, done, much, week, britt, went,...</td>\n",
       "      <td>[hmmmm, havent, done, much, week, britt, went,...</td>\n",
       "      <td>[(hmmmm, NN), (havent, NN), (done, VBN), (much...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i'm not even sure what memorial day is suppose...</td>\n",
       "      <td>F</td>\n",
       "      <td>im even sure memorial day supposed celebrate v...</td>\n",
       "      <td>[im, even, sure, memorial, day, supposed, cele...</td>\n",
       "      <td>[im, even, sure, memori, day, suppos, celebr, ...</td>\n",
       "      <td>[im, even, sure, memorial, day, supposed, cele...</td>\n",
       "      <td>[(im, RB), (even, RB), (sure, JJ), (memorial, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ok, so we are having a classic book crisis at ...</td>\n",
       "      <td>F</td>\n",
       "      <td>ok classic book crisis housewe cannot find har...</td>\n",
       "      <td>[ok, classic, book, crisis, housewe, can, not,...</td>\n",
       "      <td>[ok, classic, book, crisi, housew, can, not, f...</td>\n",
       "      <td>[ok, classic, book, crisis, housewe, can, not,...</td>\n",
       "      <td>[(ok, JJ), (classic, JJ), (book, NN), (crisis,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>urlLink    Steve Newton talking to Laura at hi...</td>\n",
       "      <td>F</td>\n",
       "      <td>urllink steve newton talking laura party urllink</td>\n",
       "      <td>[urllink, steve, newton, talking, laura, party...</td>\n",
       "      <td>[urllink, steve, newton, talk, laura, parti, u...</td>\n",
       "      <td>[urllink, steve, newton, talking, laura, party...</td>\n",
       "      <td>[(urllink, JJ), (steve, VBP), (newton, NN), (t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text class  \\\n",
       "0  I just got word that I was not cast in the Law...     M   \n",
       "1  Hmmmm, I haven't done much this week. Me and B...     M   \n",
       "2  i'm not even sure what memorial day is suppose...     F   \n",
       "3  ok, so we are having a classic book crisis at ...     F   \n",
       "4  urlLink    Steve Newton talking to Laura at hi...     F   \n",
       "\n",
       "                                          text_clean  \\\n",
       "0  got word cast law order episode good news cast...   \n",
       "1  hmmmm havent done much week britt went mall ge...   \n",
       "2  im even sure memorial day supposed celebrate v...   \n",
       "3  ok classic book crisis housewe cannot find har...   \n",
       "4   urllink steve newton talking laura party urllink   \n",
       "\n",
       "                                         text_tokens  \\\n",
       "0  [got, word, cast, law, order, episode, good, n...   \n",
       "1  [hmmmm, havent, done, much, week, britt, went,...   \n",
       "2  [im, even, sure, memorial, day, supposed, cele...   \n",
       "3  [ok, classic, book, crisis, housewe, can, not,...   \n",
       "4  [urllink, steve, newton, talking, laura, party...   \n",
       "\n",
       "                                    text_tokens_stem  \\\n",
       "0  [got, word, cast, law, order, episod, good, ne...   \n",
       "1  [hmmmm, havent, done, much, week, britt, went,...   \n",
       "2  [im, even, sure, memori, day, suppos, celebr, ...   \n",
       "3  [ok, classic, book, crisi, housew, can, not, f...   \n",
       "4  [urllink, steve, newton, talk, laura, parti, u...   \n",
       "\n",
       "                                   text_tokens_lemma  \\\n",
       "0  [got, word, cast, law, order, episode, good, n...   \n",
       "1  [hmmmm, havent, done, much, week, britt, went,...   \n",
       "2  [im, even, sure, memorial, day, supposed, cele...   \n",
       "3  [ok, classic, book, crisis, housewe, can, not,...   \n",
       "4  [urllink, steve, newton, talking, laura, party...   \n",
       "\n",
       "                              text_tokens_pos_tagged  \n",
       "0  [(got, VBD), (word, NN), (cast, NN), (law, NN)...  \n",
       "1  [(hmmmm, NN), (havent, NN), (done, VBN), (much...  \n",
       "2  [(im, RB), (even, RB), (sure, JJ), (memorial, ...  \n",
       "3  [(ok, JJ), (classic, JJ), (book, NN), (crisis,...  \n",
       "4  [(urllink, JJ), (steve, VBP), (newton, NN), (t...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#part of speech tagging and chunking\n",
    "def word_pos_tagger(text):\n",
    "    pos_tagged_text = nltk.pos_tag(text)\n",
    "    return pos_tagged_text\n",
    "\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "data_clean['text_tokens_pos_tagged'] = data_clean['text_tokens'].apply(lambda x: word_pos_tagger(x))\n",
    "data_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>text_tokens</th>\n",
       "      <th>text_tokens_stem</th>\n",
       "      <th>text_tokens_lemma</th>\n",
       "      <th>text_tokens_pos_tagged</th>\n",
       "      <th>fine</th>\n",
       "      <th>clean_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15919</th>\n",
       "      <td>Today started work at 11am, so got to wake up ...</td>\n",
       "      <td>M</td>\n",
       "      <td>today started work got wake late tis morning t...</td>\n",
       "      <td>[today, started, work, got, wake, late, tis, m...</td>\n",
       "      <td>[today, start, work, got, wake, late, ti, morn...</td>\n",
       "      <td>[today, started, work, got, wake, late, ti, mo...</td>\n",
       "      <td>[(today, NN), (started, VBD), (work, NN), (got...</td>\n",
       "      <td>today started work wake late morning might suz...</td>\n",
       "      <td>1241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28138</th>\n",
       "      <td>urlLink    LETS PLAY POCKER!!!!!!!!!!! Y DO GI...</td>\n",
       "      <td>F</td>\n",
       "      <td>urllink lets play pocker girls never know play...</td>\n",
       "      <td>[urllink, lets, play, pocker, girls, never, kn...</td>\n",
       "      <td>[urllink, let, play, pocker, girl, never, know...</td>\n",
       "      <td>[urllink, let, play, pocker, girl, never, know...</td>\n",
       "      <td>[(urllink, JJ), (lets, NNS), (play, VBP), (poc...</td>\n",
       "      <td>urllink play pocker girl never know play pocke...</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55266</th>\n",
       "      <td>(At Blockbuster) Austin: Is that Cate Blanchet...</td>\n",
       "      <td>F</td>\n",
       "      <td>blockbuster austin cate blanchett getting sara...</td>\n",
       "      <td>[blockbuster, austin, cate, blanchett, getting...</td>\n",
       "      <td>[blockbust, austin, cate, blanchett, get, sara...</td>\n",
       "      <td>[blockbuster, austin, cate, blanchett, getting...</td>\n",
       "      <td>[(blockbuster, NN), (austin, NN), (cate, NN), ...</td>\n",
       "      <td>blockbuster austin cate blanchett getting sara...</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172632</th>\n",
       "      <td>Hello everybody. I kind of forgot about the bl...</td>\n",
       "      <td>M</td>\n",
       "      <td>hello everybody kind forgot blog today miss do...</td>\n",
       "      <td>[hello, everybody, kind, forgot, blog, today, ...</td>\n",
       "      <td>[hello, everybodi, kind, forgot, blog, today, ...</td>\n",
       "      <td>[hello, everybody, kind, forgot, blog, today, ...</td>\n",
       "      <td>[(hello, NN), (everybody, NN), (kind, NN), (fo...</td>\n",
       "      <td>hello everybody kind forgot blog today miss do...</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91488</th>\n",
       "      <td>So I'm thinking about all the things that I th...</td>\n",
       "      <td>F</td>\n",
       "      <td>im thinking things think wrong family know im ...</td>\n",
       "      <td>[im, thinking, things, think, wrong, family, k...</td>\n",
       "      <td>[im, think, thing, think, wrong, famili, know,...</td>\n",
       "      <td>[im, thinking, thing, think, wrong, family, kn...</td>\n",
       "      <td>[(im, NN), (thinking, VBG), (things, NNS), (th...</td>\n",
       "      <td>thinking thing think wrong family know faultle...</td>\n",
       "      <td>1779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43531</th>\n",
       "      <td>Wowsers.  Lots and lots and lots of stuffs hap...</td>\n",
       "      <td>F</td>\n",
       "      <td>wowsers lots lots lots stuffs happened friday ...</td>\n",
       "      <td>[wowsers, lots, lots, lots, stuffs, happened, ...</td>\n",
       "      <td>[wowser, lot, lot, lot, stuff, happen, friday,...</td>\n",
       "      <td>[wowsers, lot, lot, lot, stuff, happened, frid...</td>\n",
       "      <td>[(wowsers, NNS), (lots, VBP), (lots, NNS), (lo...</td>\n",
       "      <td>wowsers stuff happened friday finished star te...</td>\n",
       "      <td>1675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25096</th>\n",
       "      <td>Hey ya'll,  I just got back from a week-long v...</td>\n",
       "      <td>F</td>\n",
       "      <td>hey yall got back weeklong vacation switzerlan...</td>\n",
       "      <td>[hey, yall, got, back, weeklong, vacation, swi...</td>\n",
       "      <td>[hey, yall, got, back, weeklong, vacat, switze...</td>\n",
       "      <td>[hey, yall, got, back, weeklong, vacation, swi...</td>\n",
       "      <td>[(hey, NN), (yall, NN), (got, VBD), (back, RB)...</td>\n",
       "      <td>yall back weeklong vacation switzerland found ...</td>\n",
       "      <td>497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137844</th>\n",
       "      <td>HEY! Christmas was of most fun! I think as you...</td>\n",
       "      <td>M</td>\n",
       "      <td>hey christmas fun think get older get realize ...</td>\n",
       "      <td>[hey, christmas, fun, think, get, older, get, ...</td>\n",
       "      <td>[hey, christma, fun, think, get, older, get, r...</td>\n",
       "      <td>[hey, christmas, fun, think, get, older, get, ...</td>\n",
       "      <td>[(hey, NN), (christmas, VBP), (fun, NN), (thin...</td>\n",
       "      <td>christmas think older realize christmas thats ...</td>\n",
       "      <td>964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79339</th>\n",
       "      <td>Fuck this  urlLink guy .  His thinks that Denn...</td>\n",
       "      <td>M</td>\n",
       "      <td>fuck urllink guy thinks dennis kucinich should...</td>\n",
       "      <td>[fuck, urllink, guy, thinks, dennis, kucinich,...</td>\n",
       "      <td>[fuck, urllink, guy, think, denni, kucinich, s...</td>\n",
       "      <td>[fuck, urllink, guy, think, dennis, kucinich, ...</td>\n",
       "      <td>[(fuck, JJ), (urllink, JJ), (guy, NN), (thinks...</td>\n",
       "      <td>fuck urllink think dennis kucinich shouldnt co...</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30904</th>\n",
       "      <td>When I was younger I thought I was invincible,...</td>\n",
       "      <td>F</td>\n",
       "      <td>younger thought invincible nothing couldnt rem...</td>\n",
       "      <td>[younger, thought, invincible, nothing, couldn...</td>\n",
       "      <td>[younger, thought, invinc, noth, couldnt, reme...</td>\n",
       "      <td>[younger, thought, invincible, nothing, couldn...</td>\n",
       "      <td>[(younger, JJR), (thought, VBD), (invincible, ...</td>\n",
       "      <td>younger thought invincible nothing couldnt rem...</td>\n",
       "      <td>1094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46480</th>\n",
       "      <td>urlLink    Dave urlLink</td>\n",
       "      <td>F</td>\n",
       "      <td>urllink dave urllink</td>\n",
       "      <td>[urllink, dave, urllink]</td>\n",
       "      <td>[urllink, dave, urllink]</td>\n",
       "      <td>[urllink, dave, urllink]</td>\n",
       "      <td>[(urllink, NN), (dave, VBP), (urllink, NN)]</td>\n",
       "      <td>urllink dave urllink</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114716</th>\n",
       "      <td>I can't find Elizabeth.  I think she was kidna...</td>\n",
       "      <td>F</td>\n",
       "      <td>cant find elizabeth think kidnapped one ineptm...</td>\n",
       "      <td>[cant, find, elizabeth, think, kidnapped, one,...</td>\n",
       "      <td>[cant, find, elizabeth, think, kidnap, one, in...</td>\n",
       "      <td>[cant, find, elizabeth, think, kidnapped, one,...</td>\n",
       "      <td>[(cant, JJ), (find, VBP), (elizabeth, JJ), (th...</td>\n",
       "      <td>cant find elizabeth think kidnapped ineptmovie...</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113912</th>\n",
       "      <td>My grandmother passed away last September leav...</td>\n",
       "      <td>F</td>\n",
       "      <td>grandmother passed away last september leaving...</td>\n",
       "      <td>[grandmother, passed, away, last, september, l...</td>\n",
       "      <td>[grandmoth, pass, away, last, septemb, leav, b...</td>\n",
       "      <td>[grandmother, passed, away, last, september, l...</td>\n",
       "      <td>[(grandmother, NN), (passed, VBD), (away, RB),...</td>\n",
       "      <td>grandmother passed away last september leaving...</td>\n",
       "      <td>2513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160250</th>\n",
       "      <td>The software that is, i've just written a info...</td>\n",
       "      <td>M</td>\n",
       "      <td>software ive written information screen peeps ...</td>\n",
       "      <td>[software, ive, written, information, screen, ...</td>\n",
       "      <td>[softwar, ive, written, inform, screen, peep, ...</td>\n",
       "      <td>[software, ive, written, information, screen, ...</td>\n",
       "      <td>[(software, NN), (ive, JJ), (written, VBN), (i...</td>\n",
       "      <td>software written information screen peep looki...</td>\n",
       "      <td>388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161564</th>\n",
       "      <td>Music. Turn on your radio. What do you hear? N...</td>\n",
       "      <td>M</td>\n",
       "      <td>music turn radio hear music hear repetitive co...</td>\n",
       "      <td>[music, turn, radio, hear, music, hear, repeti...</td>\n",
       "      <td>[music, turn, radio, hear, music, hear, repeti...</td>\n",
       "      <td>[music, turn, radio, hear, music, hear, repeti...</td>\n",
       "      <td>[(music, NN), (turn, NN), (radio, NN), (hear, ...</td>\n",
       "      <td>music turn radio hear music hear repetitive co...</td>\n",
       "      <td>921</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text class  \\\n",
       "15919   Today started work at 11am, so got to wake up ...     M   \n",
       "28138   urlLink    LETS PLAY POCKER!!!!!!!!!!! Y DO GI...     F   \n",
       "55266   (At Blockbuster) Austin: Is that Cate Blanchet...     F   \n",
       "172632  Hello everybody. I kind of forgot about the bl...     M   \n",
       "91488   So I'm thinking about all the things that I th...     F   \n",
       "43531   Wowsers.  Lots and lots and lots of stuffs hap...     F   \n",
       "25096   Hey ya'll,  I just got back from a week-long v...     F   \n",
       "137844  HEY! Christmas was of most fun! I think as you...     M   \n",
       "79339   Fuck this  urlLink guy .  His thinks that Denn...     M   \n",
       "30904   When I was younger I thought I was invincible,...     F   \n",
       "46480                             urlLink    Dave urlLink     F   \n",
       "114716  I can't find Elizabeth.  I think she was kidna...     F   \n",
       "113912  My grandmother passed away last September leav...     F   \n",
       "160250  The software that is, i've just written a info...     M   \n",
       "161564  Music. Turn on your radio. What do you hear? N...     M   \n",
       "\n",
       "                                               text_clean  \\\n",
       "15919   today started work got wake late tis morning t...   \n",
       "28138   urllink lets play pocker girls never know play...   \n",
       "55266   blockbuster austin cate blanchett getting sara...   \n",
       "172632  hello everybody kind forgot blog today miss do...   \n",
       "91488   im thinking things think wrong family know im ...   \n",
       "43531   wowsers lots lots lots stuffs happened friday ...   \n",
       "25096   hey yall got back weeklong vacation switzerlan...   \n",
       "137844  hey christmas fun think get older get realize ...   \n",
       "79339   fuck urllink guy thinks dennis kucinich should...   \n",
       "30904   younger thought invincible nothing couldnt rem...   \n",
       "46480                                urllink dave urllink   \n",
       "114716  cant find elizabeth think kidnapped one ineptm...   \n",
       "113912  grandmother passed away last september leaving...   \n",
       "160250  software ive written information screen peeps ...   \n",
       "161564  music turn radio hear music hear repetitive co...   \n",
       "\n",
       "                                              text_tokens  \\\n",
       "15919   [today, started, work, got, wake, late, tis, m...   \n",
       "28138   [urllink, lets, play, pocker, girls, never, kn...   \n",
       "55266   [blockbuster, austin, cate, blanchett, getting...   \n",
       "172632  [hello, everybody, kind, forgot, blog, today, ...   \n",
       "91488   [im, thinking, things, think, wrong, family, k...   \n",
       "43531   [wowsers, lots, lots, lots, stuffs, happened, ...   \n",
       "25096   [hey, yall, got, back, weeklong, vacation, swi...   \n",
       "137844  [hey, christmas, fun, think, get, older, get, ...   \n",
       "79339   [fuck, urllink, guy, thinks, dennis, kucinich,...   \n",
       "30904   [younger, thought, invincible, nothing, couldn...   \n",
       "46480                            [urllink, dave, urllink]   \n",
       "114716  [cant, find, elizabeth, think, kidnapped, one,...   \n",
       "113912  [grandmother, passed, away, last, september, l...   \n",
       "160250  [software, ive, written, information, screen, ...   \n",
       "161564  [music, turn, radio, hear, music, hear, repeti...   \n",
       "\n",
       "                                         text_tokens_stem  \\\n",
       "15919   [today, start, work, got, wake, late, ti, morn...   \n",
       "28138   [urllink, let, play, pocker, girl, never, know...   \n",
       "55266   [blockbust, austin, cate, blanchett, get, sara...   \n",
       "172632  [hello, everybodi, kind, forgot, blog, today, ...   \n",
       "91488   [im, think, thing, think, wrong, famili, know,...   \n",
       "43531   [wowser, lot, lot, lot, stuff, happen, friday,...   \n",
       "25096   [hey, yall, got, back, weeklong, vacat, switze...   \n",
       "137844  [hey, christma, fun, think, get, older, get, r...   \n",
       "79339   [fuck, urllink, guy, think, denni, kucinich, s...   \n",
       "30904   [younger, thought, invinc, noth, couldnt, reme...   \n",
       "46480                            [urllink, dave, urllink]   \n",
       "114716  [cant, find, elizabeth, think, kidnap, one, in...   \n",
       "113912  [grandmoth, pass, away, last, septemb, leav, b...   \n",
       "160250  [softwar, ive, written, inform, screen, peep, ...   \n",
       "161564  [music, turn, radio, hear, music, hear, repeti...   \n",
       "\n",
       "                                        text_tokens_lemma  \\\n",
       "15919   [today, started, work, got, wake, late, ti, mo...   \n",
       "28138   [urllink, let, play, pocker, girl, never, know...   \n",
       "55266   [blockbuster, austin, cate, blanchett, getting...   \n",
       "172632  [hello, everybody, kind, forgot, blog, today, ...   \n",
       "91488   [im, thinking, thing, think, wrong, family, kn...   \n",
       "43531   [wowsers, lot, lot, lot, stuff, happened, frid...   \n",
       "25096   [hey, yall, got, back, weeklong, vacation, swi...   \n",
       "137844  [hey, christmas, fun, think, get, older, get, ...   \n",
       "79339   [fuck, urllink, guy, think, dennis, kucinich, ...   \n",
       "30904   [younger, thought, invincible, nothing, couldn...   \n",
       "46480                            [urllink, dave, urllink]   \n",
       "114716  [cant, find, elizabeth, think, kidnapped, one,...   \n",
       "113912  [grandmother, passed, away, last, september, l...   \n",
       "160250  [software, ive, written, information, screen, ...   \n",
       "161564  [music, turn, radio, hear, music, hear, repeti...   \n",
       "\n",
       "                                   text_tokens_pos_tagged  \\\n",
       "15919   [(today, NN), (started, VBD), (work, NN), (got...   \n",
       "28138   [(urllink, JJ), (lets, NNS), (play, VBP), (poc...   \n",
       "55266   [(blockbuster, NN), (austin, NN), (cate, NN), ...   \n",
       "172632  [(hello, NN), (everybody, NN), (kind, NN), (fo...   \n",
       "91488   [(im, NN), (thinking, VBG), (things, NNS), (th...   \n",
       "43531   [(wowsers, NNS), (lots, VBP), (lots, NNS), (lo...   \n",
       "25096   [(hey, NN), (yall, NN), (got, VBD), (back, RB)...   \n",
       "137844  [(hey, NN), (christmas, VBP), (fun, NN), (thin...   \n",
       "79339   [(fuck, JJ), (urllink, JJ), (guy, NN), (thinks...   \n",
       "30904   [(younger, JJR), (thought, VBD), (invincible, ...   \n",
       "46480         [(urllink, NN), (dave, VBP), (urllink, NN)]   \n",
       "114716  [(cant, JJ), (find, VBP), (elizabeth, JJ), (th...   \n",
       "113912  [(grandmother, NN), (passed, VBD), (away, RB),...   \n",
       "160250  [(software, NN), (ive, JJ), (written, VBN), (i...   \n",
       "161564  [(music, NN), (turn, NN), (radio, NN), (hear, ...   \n",
       "\n",
       "                                                     fine  clean_length  \n",
       "15919   today started work wake late morning might suz...          1241  \n",
       "28138   urllink play pocker girl never know play pocke...            55  \n",
       "55266   blockbuster austin cate blanchett getting sara...           191  \n",
       "172632  hello everybody kind forgot blog today miss do...           108  \n",
       "91488   thinking thing think wrong family know faultle...          1779  \n",
       "43531   wowsers stuff happened friday finished star te...          1675  \n",
       "25096   yall back weeklong vacation switzerland found ...           497  \n",
       "137844  christmas think older realize christmas thats ...           964  \n",
       "79339   fuck urllink think dennis kucinich shouldnt co...           220  \n",
       "30904   younger thought invincible nothing couldnt rem...          1094  \n",
       "46480                                urllink dave urllink            20  \n",
       "114716  cant find elizabeth think kidnapped ineptmovie...           124  \n",
       "113912  grandmother passed away last september leaving...          2513  \n",
       "160250  software written information screen peep looki...           388  \n",
       "161564  music turn radio hear music hear repetitive co...           921  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove short words less than 3\n",
    "data_clean['fine'] = data_clean['text_tokens_lemma'].apply(lambda x: ' '.join([w for w in x if len(w)>3]))\n",
    "# Count the length of characters\n",
    "data_clean['clean_length'] = data_clean['fine'].apply(len)\n",
    "# Remove rows where character length <= 5\n",
    "data_clean = data_clean[data_clean.clean_length > 5]\n",
    "data_clean.sample(n=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(198645, 9)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sample(text):\n",
    "    #clean text\n",
    "    newText = text.str.lower()\n",
    "    newText = newText.apply(lambda elem: re.sub(r\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", elem))\n",
    "    newText = newText.apply(lambda elem: re.sub(r\"\\d+\", \"\", elem))\n",
    "    #stopwords\n",
    "    from nltk.corpus import stopwords\n",
    "    stop = stopwords.words('english')\n",
    "    newText = newText.apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "    #stemmer\n",
    "    newText = newText.apply(lambda x: word_tokenize(x))\n",
    "    newText_stem = newText.apply(lambda x: word_stemmer(x))\n",
    "    #token lemma\n",
    "    newText_lem = newText.apply(lambda x: word_lemmatizer(x))\n",
    "    newText_tag = newText.apply(lambda x: word_pos_tagger(x))\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare X and Y data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pub.towardsai.net/does-a-machine-know-your-gender-based-on-your-tweets-43b14740fd54"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaaa</th>\n",
       "      <th>aaaaa</th>\n",
       "      <th>aaaaaa</th>\n",
       "      <th>aaaaaaa</th>\n",
       "      <th>aaaaaaaa</th>\n",
       "      <th>aaaaaaaaa</th>\n",
       "      <th>aaaaaaaaaaa</th>\n",
       "      <th>aaaaaaaaaaaa</th>\n",
       "      <th>aaaaaaaaaaaaa</th>\n",
       "      <th>aaaaaaaaaaaaaa</th>\n",
       "      <th>...</th>\n",
       "      <th>zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz</th>\n",
       "      <th>zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz</th>\n",
       "      <th>zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz</th>\n",
       "      <th>zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz</th>\n",
       "      <th>zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz</th>\n",
       "      <th>zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz</th>\n",
       "      <th>zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz</th>\n",
       "      <th>zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz</th>\n",
       "      <th>zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz</th>\n",
       "      <th>zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198640</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198641</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198642</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198643</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198644</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198645 rows × 532870 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        aaaa  aaaaa  aaaaaa  aaaaaaa  aaaaaaaa  aaaaaaaaa  aaaaaaaaaaa  \\\n",
       "0          0      0       0        0         0          0            0   \n",
       "1          0      0       0        0         0          0            0   \n",
       "2          0      0       0        0         0          0            0   \n",
       "3          0      0       0        0         0          0            0   \n",
       "4          0      0       0        0         0          0            0   \n",
       "...      ...    ...     ...      ...       ...        ...          ...   \n",
       "198640     0      0       0        0         0          0            0   \n",
       "198641     0      0       0        0         0          0            0   \n",
       "198642     0      0       0        0         0          0            0   \n",
       "198643     0      0       0        0         0          0            0   \n",
       "198644     0      0       0        0         0          0            0   \n",
       "\n",
       "        aaaaaaaaaaaa  aaaaaaaaaaaaa  aaaaaaaaaaaaaa  ...  \\\n",
       "0                  0              0               0  ...   \n",
       "1                  0              0               0  ...   \n",
       "2                  0              0               0  ...   \n",
       "3                  0              0               0  ...   \n",
       "4                  0              0               0  ...   \n",
       "...              ...            ...             ...  ...   \n",
       "198640             0              0               0  ...   \n",
       "198641             0              0               0  ...   \n",
       "198642             0              0               0  ...   \n",
       "198643             0              0               0  ...   \n",
       "198644             0              0               0  ...   \n",
       "\n",
       "        zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz  \\\n",
       "0                                        0   \n",
       "1                                        0   \n",
       "2                                        0   \n",
       "3                                        0   \n",
       "4                                        0   \n",
       "...                                    ...   \n",
       "198640                                   0   \n",
       "198641                                   0   \n",
       "198642                                   0   \n",
       "198643                                   0   \n",
       "198644                                   0   \n",
       "\n",
       "        zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz  \\\n",
       "0                                             0   \n",
       "1                                             0   \n",
       "2                                             0   \n",
       "3                                             0   \n",
       "4                                             0   \n",
       "...                                         ...   \n",
       "198640                                        0   \n",
       "198641                                        0   \n",
       "198642                                        0   \n",
       "198643                                        0   \n",
       "198644                                        0   \n",
       "\n",
       "        zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz  \\\n",
       "0                                              0   \n",
       "1                                              0   \n",
       "2                                              0   \n",
       "3                                              0   \n",
       "4                                              0   \n",
       "...                                          ...   \n",
       "198640                                         0   \n",
       "198641                                         0   \n",
       "198642                                         0   \n",
       "198643                                         0   \n",
       "198644                                         0   \n",
       "\n",
       "        zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz  \\\n",
       "0                                                     0   \n",
       "1                                                     0   \n",
       "2                                                     0   \n",
       "3                                                     0   \n",
       "4                                                     0   \n",
       "...                                                 ...   \n",
       "198640                                                0   \n",
       "198641                                                0   \n",
       "198642                                                0   \n",
       "198643                                                0   \n",
       "198644                                                0   \n",
       "\n",
       "        zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz  \\\n",
       "0                                                       0        \n",
       "1                                                       0        \n",
       "2                                                       0        \n",
       "3                                                       0        \n",
       "4                                                       0        \n",
       "...                                                   ...        \n",
       "198640                                                  0        \n",
       "198641                                                  0        \n",
       "198642                                                  0        \n",
       "198643                                                  0        \n",
       "198644                                                  0        \n",
       "\n",
       "        zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz  \\\n",
       "0                                                       0         \n",
       "1                                                       0         \n",
       "2                                                       0         \n",
       "3                                                       0         \n",
       "4                                                       0         \n",
       "...                                                   ...         \n",
       "198640                                                  0         \n",
       "198641                                                  0         \n",
       "198642                                                  0         \n",
       "198643                                                  0         \n",
       "198644                                                  0         \n",
       "\n",
       "        zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz  \\\n",
       "0                                                       0           \n",
       "1                                                       0           \n",
       "2                                                       0           \n",
       "3                                                       0           \n",
       "4                                                       0           \n",
       "...                                                   ...           \n",
       "198640                                                  0           \n",
       "198641                                                  0           \n",
       "198642                                                  0           \n",
       "198643                                                  0           \n",
       "198644                                                  0           \n",
       "\n",
       "        zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz  \\\n",
       "0                                                       0                   \n",
       "1                                                       0                   \n",
       "2                                                       0                   \n",
       "3                                                       0                   \n",
       "4                                                       0                   \n",
       "...                                                   ...                   \n",
       "198640                                                  0                   \n",
       "198641                                                  0                   \n",
       "198642                                                  0                   \n",
       "198643                                                  0                   \n",
       "198644                                                  0                   \n",
       "\n",
       "        zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz  \\\n",
       "0                                                       0                    \n",
       "1                                                       0                    \n",
       "2                                                       0                    \n",
       "3                                                       0                    \n",
       "4                                                       0                    \n",
       "...                                                   ...                    \n",
       "198640                                                  0                    \n",
       "198641                                                  0                    \n",
       "198642                                                  0                    \n",
       "198643                                                  0                    \n",
       "198644                                                  0                    \n",
       "\n",
       "        zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz  \n",
       "0                                                       0                                            \n",
       "1                                                       0                                            \n",
       "2                                                       0                                            \n",
       "3                                                       0                                            \n",
       "4                                                       0                                            \n",
       "...                                                   ...                                            \n",
       "198640                                                  0                                            \n",
       "198641                                                  0                                            \n",
       "198642                                                  0                                            \n",
       "198643                                                  0                                            \n",
       "198644                                                  0                                            \n",
       "\n",
       "[198645 rows x 532870 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import libraries\n",
    "#from sklearn.feature_extraction.text import CountVectorizer\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn.metrics import f1_score\n",
    "# Bag-of-words features\n",
    "bow_vectorizer = CountVectorizer(stop_words='english')\n",
    "# Bag-of-words feature matrix\n",
    "bow = bow_vectorizer.fit_transform(data_clean['fine'])\n",
    "df_bow = pd.DataFrame(bow.todense(), columns=bow_vectorizer.get_feature_names())\n",
    "df_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean['gender'] = data_clean['class'].apply(lambda x: 1 if x=='F' else 0)\n",
    "# Splitting the data into training and test set\n",
    "X = df_bow\n",
    "y = data_clean['gender']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting on Logistic Regression model\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "prediction_bow = logreg.predict_proba(X_test)\n",
    "# Calculating the F1 score\n",
    "# If prediction is greater than or equal to 0.5 than 1, else 0\n",
    "# Gender, 0 = male and 1 = female\n",
    "prediction_int = prediction_bow[:,1]>=0.5\n",
    "prediction_int = prediction_int.astype(np.int)\n",
    "# Calculating F1 score\n",
    "log_bow = f1_score(y_test, prediction_int)\n",
    "log_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use score method to get accuracy of model\n",
    "score = logreg.score(X_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "cm = metrics.confusion_matrix(y_test, predictions)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/machine-learning-nlp-text-classification-using-scikit-learn-python-and-nltk-c52b92a7c73a\n",
    "\n",
    "https://towardsdatascience.com/building-a-logistic-regression-in-python-step-by-step-becd4d56c9c8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = clf.predict(X_test)\n",
    "np.mean(predicted == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.pipeline import Pipeline\n",
    "#from sklearn.feature_extraction.text import TfidfTransformer\n",
    "#text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "#                      ('tfidf', TfidfTransformer()),\n",
    "#                      ('clf', MultinomialNB()),\n",
    " #                      ])\n",
    "#text_clf = text_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicted = text_clf.predict(X_test)\n",
    "#np.mean(predicted == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "clf_svm = SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, n_iter_no_change=5, random_state=42)\n",
    "_ = clf_svm.fit(X_train, y_train)\n",
    "predicted_svm = clf_svm.predict(X_test)\n",
    "np.mean(predicted_svm == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = text_df[\"text\"]\n",
    "y1 = text_df[\"class\"].apply(lambda x: 1 if x=='F' else 0)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X1, y1, test_size=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/machine-learning-nlp-text-classification-using-scikit-learn-python-and-nltk-c52b92a7c73a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\", ignore_stopwords=True)\n",
    "class StemmedCountVectorizer(CountVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(StemmedCountVectorizer, self).build_analyzer()\n",
    "        return lambda doc: ([stemmer.stem(w) for w in analyzer(doc)])\n",
    "stemmed_count_vect = StemmedCountVectorizer(stop_words='english')\n",
    "text_mnb_stemmed = Pipeline([('vect', stemmed_count_vect),\n",
    "                      ('tfidf', TfidfTransformer()),\n",
    "                      ('mnb', MultinomialNB(fit_prior=False)),\n",
    " ])\n",
    "text_mnb_stemmed = text_mnb_stemmed.fit(X_train2, y_train2)\n",
    "predicted_mnb_stemmed = text_mnb_stemmed.predict(X_test2)\n",
    "np.mean(predicted_mnb_stemmed == y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply Neuron Network: https://realpython.com/python-keras-text-classification/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
